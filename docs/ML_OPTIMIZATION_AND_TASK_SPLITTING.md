# ðŸ§  Machine Learning Optimization & Task Separation

## Part 1: ML-Based Peer Optimization

### **What the ML System Learns:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ML LEARNING OBJECTIVES                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ 1. Peer Performance Prediction                                 â”‚
â”‚    Input:  [peer_id, task_type, time_of_day, current_load]    â”‚
â”‚    Output: Expected completion time (95% confidence)           â”‚
â”‚                                                                 â”‚
â”‚ 2. Optimal Task Assignment                                     â”‚
â”‚    Input:  [task_requirements, available_peers, latency_budget]â”‚
â”‚    Output: Best peer_id + backup peers                         â”‚
â”‚                                                                 â”‚
â”‚ 3. Adaptive Load Balancing                                     â”‚
â”‚    Input:  [peer_history, current_system_load, user_location] â”‚
â”‚    Output: How many tasks to send to each peer                 â”‚
â”‚                                                                 â”‚
â”‚ 4. Failure Prediction                                          â”‚
â”‚    Input:  [peer_telemetry, recent_failures, network_metrics] â”‚
â”‚    Output: Probability of failure in next 60 seconds          â”‚
â”‚                                                                 â”‚
â”‚ 5. Latency Optimization                                        â”‚
â”‚    Input:  [peer_location, time_of_day, ISP, routing_path]    â”‚
â”‚    Output: Predicted latency for next request                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **ML Architecture:**

```python
# Enhanced Coordinator with ML
class MLCoordinator(Coordinator):
    """
    Coordinator with machine learning optimization.
    
    Learns from historical data to:
    - Predict peer performance
    - Optimize task assignments
    - Adapt to network conditions
    - Prevent failures proactively
    """
    
    def __init__(self):
        super().__init__()
        
        # ML Models
        self.performance_predictor = PerformancePredictor()
        self.task_assigner = TaskAssignmentModel()
        self.failure_predictor = FailurePredictor()
        
        # Learning history
        self.task_history = []  # Past 10,000 tasks
        self.peer_performance_db = {}  # Detailed peer stats
        self.network_conditions_log = []  # Time-series data
        
    async def schedule_task_ml(self, task: Task) -> None:
        """
        ML-enhanced task scheduling.
        
        Steps:
        1. Predict completion time for each peer
        2. Consider failure probability
        3. Factor in current network conditions
        4. Choose optimal peer + 2 backups
        5. Monitor and learn from result
        """
        
        # Get predictions for all peers
        candidates = []
        for peer_id, peer in self.peers.items():
            
            # Predict performance
            prediction = self.performance_predictor.predict(
                peer_id=peer_id,
                task_type=task.constraints['type'],
                time_of_day=current_time(),
                current_load=peer.in_flight,
                historical_data=self.peer_performance_db[peer_id]
            )
            
            # Predict failure probability
            failure_prob = self.failure_predictor.predict(
                peer_telemetry=peer.heartbeat(),
                recent_failures=self.get_recent_failures(peer_id),
                network_metrics=self.get_network_metrics(peer_id)
            )
            
            # Calculate expected value
            expected_time = prediction['completion_time']
            confidence = prediction['confidence']
            risk_adjusted_time = expected_time / (1 - failure_prob)
            
            candidates.append({
                'peer': peer,
                'expected_time': expected_time,
                'confidence': confidence,
                'failure_risk': failure_prob,
                'risk_adjusted_time': risk_adjusted_time,
                'score': self._calculate_ml_score(expected_time, confidence, failure_prob)
            })
        
        # Sort by score (lower is better)
        candidates.sort(key=lambda x: x['score'])
        
        # Select primary + backups
        primary = candidates[0]['peer']
        backup1 = candidates[1]['peer'] if len(candidates) > 1 else None
        backup2 = candidates[2]['peer'] if len(candidates) > 2 else None
        
        # Execute with proactive failover
        result = await self._execute_with_ml_failover(
            task, primary, backup1, backup2,
            expected_time=candidates[0]['expected_time']
        )
        
        # Learn from result
        self._record_and_learn(task, primary, result, candidates[0])
        
        return result
```

### **Performance Predictor Model:**

```python
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor

class PerformancePredictor:
    """
    Predicts task completion time based on historical data.
    
    Features:
    - Peer characteristics (GPU, CPU, network)
    - Task characteristics (type, size, complexity)
    - Temporal features (time of day, day of week)
    - Environmental features (other load, network congestion)
    """
    
    def __init__(self):
        self.model = GradientBoostingRegressor(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=5
        )
        self.feature_scaler = StandardScaler()
        self.is_trained = False
        
    def extract_features(self, peer_id, task_type, time_of_day, 
                        current_load, historical_data):
        """Extract ML features from inputs."""
        
        features = []
        
        # Peer features
        peer_stats = historical_data['stats']
        features.extend([
            peer_stats['avg_completion_time'],
            peer_stats['std_completion_time'],
            peer_stats['success_rate'],
            peer_stats['avg_latency'],
            peer_stats['gpu_score'],
            peer_stats['cpu_score'],
        ])
        
        # Task features
        task_complexity = self._get_task_complexity(task_type)
        features.extend([
            task_complexity['compute_score'],
            task_complexity['memory_score'],
            task_complexity['bandwidth_score'],
        ])
        
        # Temporal features (cyclical encoding)
        hour = time_of_day.hour
        features.extend([
            np.sin(2 * np.pi * hour / 24),  # Hour of day (cyclical)
            np.cos(2 * np.pi * hour / 24),
            time_of_day.weekday(),  # Day of week
            1 if time_of_day.weekday() >= 5 else 0,  # Is weekend
        ])
        
        # Load features
        features.extend([
            current_load,  # Current tasks
            historical_data['avg_load_at_this_hour'],  # Historical load
            self._get_system_load(),  # Overall system load
        ])
        
        # Network features
        network_stats = historical_data['network']
        features.extend([
            network_stats['avg_latency'],
            network_stats['jitter'],
            network_stats['packet_loss'],
            network_stats['congestion_score'],
        ])
        
        return np.array(features)
    
    def predict(self, peer_id, task_type, time_of_day, 
               current_load, historical_data):
        """
        Predict completion time for a task on a peer.
        
        Returns:
            {
                'completion_time': float (milliseconds),
                'confidence': float (0-1),
                'lower_bound': float (95% CI),
                'upper_bound': float (95% CI)
            }
        """
        
        if not self.is_trained:
            # Use heuristic until we have training data
            return self._heuristic_prediction(historical_data)
        
        features = self.extract_features(
            peer_id, task_type, time_of_day, 
            current_load, historical_data
        )
        
        features_scaled = self.feature_scaler.transform([features])
        
        # Get prediction + confidence interval
        prediction = self.model.predict(features_scaled)[0]
        
        # Estimate confidence from historical variance
        historical_variance = historical_data['stats']['std_completion_time']
        confidence = 1.0 - min(1.0, historical_variance / prediction)
        
        return {
            'completion_time': prediction,
            'confidence': confidence,
            'lower_bound': prediction - 2 * historical_variance,
            'upper_bound': prediction + 2 * historical_variance
        }
    
    def train(self, training_data):
        """
        Train model on historical data.
        
        Args:
            training_data: List of {features, actual_completion_time}
        """
        X = [d['features'] for d in training_data]
        y = [d['actual_completion_time'] for d in training_data]
        
        X_scaled = self.feature_scaler.fit_transform(X)
        self.model.fit(X_scaled, y)
        self.is_trained = True
```

### **Adaptive Load Balancing:**

```python
class AdaptiveLoadBalancer:
    """
    Learns optimal load distribution across peers.
    
    Uses reinforcement learning to maximize:
    - Throughput (tasks/second)
    - Minimize latency
    - Balance load fairly
    - Adapt to changing conditions
    """
    
    def __init__(self):
        self.q_table = {}  # State-action values
        self.learning_rate = 0.1
        self.discount_factor = 0.95
        self.epsilon = 0.1  # Exploration rate
        
    def get_load_distribution(self, peers, pending_tasks):
        """
        Decide how many tasks to assign to each peer.
        
        State: (system_load, peer_capacities, network_conditions)
        Actions: Distribution of tasks across peers
        Reward: -latency - failures + throughput
        """
        
        state = self._encode_state(peers, pending_tasks)
        
        if random.random() < self.epsilon:
            # Explore: Try random distribution
            action = self._random_distribution(peers, pending_tasks)
        else:
            # Exploit: Use learned policy
            action = self._best_action(state, peers, pending_tasks)
        
        return action
    
    def update_policy(self, state, action, reward, next_state):
        """Update Q-table based on outcome."""
        
        state_key = self._state_to_key(state)
        action_key = self._action_to_key(action)
        
        if state_key not in self.q_table:
            self.q_table[state_key] = {}
        
        current_q = self.q_table[state_key].get(action_key, 0.0)
        
        # Q-learning update
        next_state_key = self._state_to_key(next_state)
        max_next_q = max(self.q_table.get(next_state_key, {}).values(), default=0.0)
        
        new_q = current_q + self.learning_rate * (
            reward + self.discount_factor * max_next_q - current_q
        )
        
        self.q_table[state_key][action_key] = new_q
    
    def calculate_reward(self, results):
        """
        Calculate reward based on task execution results.
        
        Reward components:
        + 10 points per successful task
        - 5 points per failed task
        - 0.1 points per ms of average latency
        + 5 points for balanced load (fairness bonus)
        """
        
        successes = sum(1 for r in results if r.status == 'success')
        failures = sum(1 for r in results if r.status == 'failure')
        avg_latency = np.mean([r.duration_ms for r in results])
        load_variance = self._calculate_load_variance()
        
        reward = (
            10 * successes
            - 5 * failures
            - 0.1 * avg_latency
            + 5 * (1.0 - load_variance)  # Bonus for balance
        )
        
        return reward
```

---

## Part 2: Task Separation Strategies

### **How to Split Tasks - The Core Challenge**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   TASK SPLITTING STRATEGIES                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ 1. SPATIAL DECOMPOSITION (Divide by space)                     â”‚
â”‚    Example: Screen divided into tiles                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚    â”‚ Tile 1  â”‚ Tile 2  â”‚ Tile 3  â”‚  Each peer renders one     â”‚
â”‚    â”‚ Peer_1  â”‚ Peer_2  â”‚ Peer_3  â”‚  tile independently        â”‚
â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                            â”‚
â”‚    â”‚ Tile 4  â”‚ Tile 5  â”‚ Tile 6  â”‚  Coordinator stitches      â”‚
â”‚    â”‚ Peer_4  â”‚ Peer_5  â”‚ Peer_6  â”‚  tiles back together       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                 â”‚
â”‚    Pros: Easy to parallelize, minimal coordination             â”‚
â”‚    Cons: Tile boundaries visible, load imbalance               â”‚
â”‚                                                                 â”‚
â”‚ 2. TEMPORAL DECOMPOSITION (Divide by time)                     â”‚
â”‚    Example: Different frames to different peers                â”‚
â”‚    Frame 0 â†’ Peer_1  (renders immediately)                     â”‚
â”‚    Frame 1 â†’ Peer_2  (renders in parallel)                     â”‚
â”‚    Frame 2 â†’ Peer_3  (renders in parallel)                     â”‚
â”‚    ...                                                          â”‚
â”‚    Coordinator reorders frames for playback                    â”‚
â”‚                                                                 â”‚
â”‚    Pros: Perfect for video encoding, no boundaries             â”‚
â”‚    Cons: Sync issues, one slow peer blocks entire stream       â”‚
â”‚                                                                 â”‚
â”‚ 3. PIPELINE DECOMPOSITION (Divide by stage)                    â”‚
â”‚    Example: Rendering pipeline stages                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚    â”‚ Geometry â”‚â”€â”€â”€â–ºâ”‚ Lighting â”‚â”€â”€â”€â–ºâ”‚  Post    â”‚              â”‚
â”‚    â”‚  Peer_1  â”‚    â”‚  Peer_2  â”‚    â”‚ Process  â”‚              â”‚
â”‚    â”‚          â”‚    â”‚          â”‚    â”‚ Peer_3   â”‚              â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                 â”‚
â”‚    Pros: Natural separation, good for specialized hardware     â”‚
â”‚    Cons: Sequential dependencies, bottleneck at slowest stage  â”‚
â”‚                                                                 â”‚
â”‚ 4. FUNCTIONAL DECOMPOSITION (Divide by task type)              â”‚
â”‚    Example: Different subsystems to different peers            â”‚
â”‚    Peer_1: Physics simulation                                  â”‚
â”‚    Peer_2: AI/NPC behavior                                     â”‚
â”‚    Peer_3: Ray tracing                                         â”‚
â”‚    Peer_4: Audio processing                                    â”‚
â”‚    Peer_5: Particle effects                                    â”‚
â”‚                                                                 â”‚
â”‚    Pros: Easy to reason about, natural specialization          â”‚
â”‚    Cons: Load imbalance, complex coordination                  â”‚
â”‚                                                                 â”‚
â”‚ 5. HYBRID DECOMPOSITION (Combine strategies)                   â”‚
â”‚    Example: Spatial + Functional                               â”‚
â”‚    - Divide screen into regions (spatial)                      â”‚
â”‚    - Within each region, split rendering stages (pipeline)     â”‚
â”‚    - Offload AI/physics separately (functional)                â”‚
â”‚                                                                 â”‚
â”‚    Pros: Maximum flexibility, optimal resource use             â”‚
â”‚    Cons: Most complex to implement                             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Concrete Implementation: Ray Tracing Decomposition**

```python
class RayTracingTaskSplitter:
    """
    Split ray tracing work across multiple peers.
    
    Strategy: Spatial decomposition with adaptive tiling
    """
    
    def split_ray_tracing_task(self, scene_data, num_peers):
        """
        Divide ray tracing work into tasks.
        
        Approach:
        1. Analyze scene complexity per region
        2. Create tiles of equal COMPUTATIONAL cost (not equal size!)
        3. Assign tiles to peers based on their capability
        
        Args:
            scene_data: {
                'resolution': (1920, 1080),
                'geometry': G-buffer data,
                'materials': Material properties,
                'lights': Light sources,
                'camera': Camera parameters
            }
            num_peers: Number of available peers
            
        Returns:
            List of tasks, one per peer
        """
        
        width, height = scene_data['resolution']
        
        # Step 1: Analyze complexity
        complexity_map = self._analyze_scene_complexity(scene_data)
        
        # Step 2: Create adaptive tiles
        tiles = self._create_adaptive_tiles(
            complexity_map, 
            num_peers, 
            target_load_balance=0.95
        )
        
        # Step 3: Create task for each tile
        tasks = []
        for i, tile in enumerate(tiles):
            task = Task(
                job_id=f"raytrace_{scene_data['frame_id']}",
                task_id=f"tile_{i}",
                payload=self._serialize_tile_data(scene_data, tile),
                deadline_ms=100,  # Ray tracing can be 100ms behind
                constraints={
                    'type': 'ray_tracing',
                    'requires_rtx': True,
                    'estimated_rays': tile['estimated_rays'],
                    'tile_bounds': tile['bounds']
                }
            )
            tasks.append(task)
        
        return tasks
    
    def _analyze_scene_complexity(self, scene_data):
        """
        Calculate computational cost for each pixel.
        
        Factors:
        - Geometry complexity (triangles per pixel)
        - Material complexity (shader complexity)
        - Lighting complexity (number of lights affecting pixel)
        - Reflection depth (how many bounces)
        """
        
        width, height = scene_data['resolution']
        complexity_map = np.zeros((height, width))
        
        geometry = scene_data['geometry']
        materials = scene_data['materials']
        lights = scene_data['lights']
        
        for y in range(height):
            for x in range(width):
                pixel_complexity = 0
                
                # Geometry complexity (from G-buffer)
                triangle_count = geometry['triangle_density'][y, x]
                pixel_complexity += triangle_count * 0.1
                
                # Material complexity
                material_id = materials['material_id'][y, x]
                material_cost = materials['shader_cost'][material_id]
                pixel_complexity += material_cost
                
                # Lighting complexity
                for light in lights:
                    if self._pixel_affected_by_light(x, y, light, geometry):
                        pixel_complexity += light['cost']
                
                # Reflection/refraction depth
                metallic = materials['metallic'][y, x]
                roughness = materials['roughness'][y, x]
                reflection_depth = self._estimate_bounce_depth(metallic, roughness)
                pixel_complexity *= (1 + reflection_depth * 0.5)
                
                complexity_map[y, x] = pixel_complexity
        
        return complexity_map
    
    def _create_adaptive_tiles(self, complexity_map, num_peers, target_load_balance):
        """
        Create tiles with equal COMPUTATIONAL cost.
        
        Uses binary space partitioning (BSP) to recursively split
        the screen until we have equal-cost tiles.
        """
        
        height, width = complexity_map.shape
        total_complexity = complexity_map.sum()
        target_complexity_per_tile = total_complexity / num_peers
        
        tiles = []
        
        def split_recursive(bounds, remaining_splits):
            """Recursively split region into equal-cost tiles."""
            
            if remaining_splits == 0:
                tiles.append({
                    'bounds': bounds,
                    'estimated_rays': self._estimate_rays(complexity_map, bounds),
                    'complexity': self._region_complexity(complexity_map, bounds)
                })
                return
            
            # Try horizontal and vertical splits
            best_split = self._find_best_split(
                complexity_map, 
                bounds, 
                target_complexity_per_tile
            )
            
            # Recursively split each half
            split_recursive(best_split['left'], remaining_splits - 1)
            split_recursive(best_split['right'], remaining_splits - 1)
        
        # Start recursive splitting
        initial_bounds = {'x': 0, 'y': 0, 'width': width, 'height': height}
        num_splits = int(np.log2(num_peers))
        split_recursive(initial_bounds, num_splits)
        
        return tiles
```

### **Physics Decomposition:**

```python
class PhysicsTaskSplitter:
    """
    Split physics simulation across peers.
    
    Strategy: Spatial + Object-based decomposition
    """
    
    def split_physics_task(self, physics_world, num_peers):
        """
        Divide physics simulation into independent subtasks.
        
        Challenges:
        - Objects interact across boundaries
        - Need to synchronize shared state
        - Must maintain determinism
        
        Solution: "Ghost zones" + Two-phase simulation
        """
        
        # Phase 1: Broad-phase collision detection (local)
        # Phase 2: Narrow-phase + integration (distributed)
        
        # Step 1: Spatial partitioning with overlap
        regions = self._partition_world_with_ghosts(
            physics_world, 
            num_peers, 
            ghost_margin=2.0  # 2 meter overlap
        )
        
        tasks = []
        for i, region in enumerate(regions):
            # Each peer simulates their region + ghost zone
            task = Task(
                job_id=f"physics_{physics_world.frame_id}",
                task_id=f"region_{i}",
                payload=self._serialize_physics_data(region),
                deadline_ms=16,  # Physics needs to be real-time!
                constraints={
                    'type': 'physics',
                    'requires_cpu_cores': 4,
                    'object_count': region['object_count'],
                    'region_bounds': region['bounds'],
                    'ghost_objects': region['ghost_objects']
                }
            )
            tasks.append(task)
        
        return tasks
    
    def merge_physics_results(self, results):
        """
        Merge physics simulation results from multiple peers.
        
        Handle conflicts in ghost zones:
        - If same object simulated by multiple peers, take average
        - Detect tunneling/penetration and re-simulate locally
        - Maintain energy conservation
        """
        
        merged_state = {}
        conflicts = []
        
        for result in results:
            for obj_id, state in result.object_states.items():
                if obj_id in merged_state:
                    # Conflict: Same object in multiple results
                    conflicts.append(obj_id)
                    # Average the states (simple approach)
                    merged_state[obj_id] = self._average_states(
                        merged_state[obj_id], 
                        state
                    )
                else:
                    merged_state[obj_id] = state
        
        # Resolve conflicts with local simulation
        if conflicts:
            merged_state = self._resolve_conflicts_local(merged_state, conflicts)
        
        return merged_state
```

---

*Want me to continue with:*
1. **AI/NPC Task Splitting** (behavior trees, pathfinding)?
2. **Texture/Asset Streaming** (LOD generation, compression)?
3. **Full Implementation** of ML coordinator with real training data?
4. **Benchmark results** showing performance improvements?
