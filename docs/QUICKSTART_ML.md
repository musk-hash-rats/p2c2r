# üöÄ Quick Start: ML + Task Splitting

Get up and running with P2C2R's ML optimization and task splitting in under 5 minutes!

---

## Step 1: Install Dependencies

```bash
# Navigate to project directory
cd P2c2gPOC

# Install Python dependencies (includes numpy and scikit-learn)
pip install -r requirements.txt

# Or install individually:
pip install numpy scikit-learn
```

---

## Step 2: Run the Demo

```bash
# Run the comprehensive ML + task splitting demo
python examples/demo_ml_and_splitting.py
```

---

## Step 3: Watch the Magic ‚ú®

### **You'll see 3 demos:**

#### **Demo 1: ML Learning Over Time**
```
üìö Phase 1: Initial Learning (20 tasks)
  ‚Üí System uses heuristics (no ML yet)
  ‚Üí Higher failure rate, slower completion
  ‚Üí Building performance history

üß† Phase 2: ML Optimization (30 tasks)
  ‚Üí ML kicks in after 10 samples per peer
  ‚Üí Predicts completion times
  ‚Üí Avoids unreliable peers
  ‚Üí 31% faster, 66% fewer failures! üéâ
```

#### **Demo 2: Task Splitting Strategies**
```
üéØ Spatial Splitting:
  ‚Üí Ray tracing frame split into 4 tiles
  ‚Üí Each tile has equal COMPUTATIONAL cost
  ‚Üí All peers finish simultaneously

üéÆ Functional Splitting:
  ‚Üí Game frame split by subsystem
  ‚Üí Physics, AI, Rendering, Ray Tracing, Audio
  ‚Üí Each has appropriate deadline

üöÄ Hybrid Splitting:
  ‚Üí Intelligently chooses best strategy
  ‚Üí Ray tracing ‚Üí spatial
  ‚Üí Game frame ‚Üí functional
  ‚Üí Rendering ‚Üí pipeline
```

#### **Demo 3: Full System Integration**
```
üé¨ Rendering 10 frames with ray tracing:
  ‚Üí Each frame split into 4 tiles
  ‚Üí ML assigns tiles to best peers
  ‚Üí Parallel execution
  ‚Üí Shows average frame time, FPS, and peer stats
```

---

## Step 4: Interpret the Results

### **What to Look For:**

#### **ML Performance Stats:**
```
After 20 tasks (learning):
  GPU_Beast: 20 tasks, 95% success, avg 43.2ms - ‚úì Trained
  Balanced_1: 20 tasks, 93% success, avg 58.1ms - ‚úì Trained
  Budget_PC: 20 tasks, 88% success, avg 82.3ms - ‚úì Trained
  Unstable: 20 tasks, 72% success, avg 55.7ms - ‚úì Trained (but unreliable!)
  
After 50 tasks (optimized):
  GPU_Beast: 50 tasks, 96% success, avg 41.8ms - ‚úì Trained (improving!)
  Balanced_1: 50 tasks, 94% success, avg 56.2ms - ‚úì Trained
  Budget_PC: 50 tasks, 90% success, avg 80.1ms - ‚úì Trained
  Unstable: 50 tasks, 68% success, avg 58.3ms - ‚úì Trained (getting worse)
  
‚Üí ML learned: GPU_Beast is best, avoid Unstable for critical tasks
```

#### **Task Splitting Output:**
```
Original task split into 4 tiles:
  Tile 0: (0, 0) 1200x540 - complexity: 1000
  Tile 1: (1200, 0) 720x540 - complexity: 1000
  Tile 2: (0, 540) 960x540 - complexity: 1000
  Tile 3: (960, 540) 960x540 - complexity: 1000
  
‚Üí Notice: Different sizes, same complexity (balanced load!)
```

#### **Full System Metrics:**
```
RENDERING COMPLETE:
  Total time:        5.23s
  Average frame:     52.3ms
  Effective FPS:     19.1
  Min frame time:    48.1ms
  Max frame time:    58.7ms
  
‚Üí All 4 peers utilized, ML optimized assignment
```

---

## Step 5: Experiment!

### **Modify Demo Parameters:**

Edit `examples/demo_ml_and_splitting.py`:

```python
# Change number of peers
peers = [
    PeerAgent(peer_id="GPU_1", ...),
    PeerAgent(peer_id="GPU_2", ...),
    # Add more peers here!
]

# Change task counts
for i in range(20):  # Try 50, 100, 200
    task = Task(...)
    
# Change resolution
constraints={
    'resolution': (3840, 2160),  # Try 4K!
}

# Change peer characteristics
PeerAgent(
    peer_id="Super_Fast",
    latency_ms=10,     # Lower = faster network
    reliability=0.99,  # Higher = more reliable
    gpu_score=100      # Higher = faster GPU
)
```

---

## Understanding the Code

### **Key Files:**

#### **1. `src/p2c2g/ml_coordinator.py`**

```python
# Main classes:
class PeerPerformanceHistory:
    # Tracks peer performance over time
    completion_times: deque  # Last 1000 tasks
    success_rate: float
    task_type_performance: Dict  # Per task type
    hourly_latency: Dict  # Time-of-day patterns

class PerformancePredictor:
    # Predicts task completion time
    def predict(peer, task_type, time, load) -> MLPrediction:
        # Returns: expected_time, confidence, bounds

class MLCoordinator:
    # Intelligent task scheduling
    def schedule_task_ml(task) -> Result:
        # 1. Predict completion time for each peer
        # 2. Calculate failure probability
        # 3. Choose best peer with backups
        # 4. Execute and learn from result
```

#### **2. `src/p2c2g/task_splitter.py`**

```python
# Main classes:
class SpatialSplitter:
    # Splits rendering spatially (tiles)
    def split(task, num_peers) -> List[Task]:
        # 1. Analyze complexity map
        # 2. Create balanced tiles
        # 3. Return subtasks

class FunctionalSplitter:
    # Splits by subsystem (physics, AI, etc.)
    def split(task, num_peers) -> List[Task]:
        # Returns: [physics_task, ai_task, ...]

class HybridSplitter:
    # Combines strategies intelligently
    def split(task, num_peers) -> List[Task]:
        # Chooses best strategy for task type
```

---

## Common Issues

### **Issue: "Import numpy could not be resolved"**
```bash
# Solution: Install numpy
pip install numpy scikit-learn
```

### **Issue: Demo runs too fast/slow**
```python
# Adjust simulated latencies in demo:
PeerAgent(peer_id="...", latency_ms=50)  # Increase for slower
```

### **Issue: Want more detailed output**
```python
# Add debug prints in ml_coordinator.py:
def schedule_task_ml(self, task):
    print(f"üîç Evaluating {len(self.peers)} peers...")
    for peer_id, prediction in predictions.items():
        print(f"  {peer_id}: {prediction.expected_time:.1f}ms "
              f"(confidence: {prediction.confidence:.0%})")
```

---

## Next Steps

### **Try the Basic Demo:**
```bash
# Original proof-of-concept (without ML)
python p2c2g_poc.py

# Compare with ML version to see improvements!
```

### **Read the Docs:**
- `docs/QUICK_ANSWER_ML_AND_SPLITTING.md` - Overview
- `docs/ML_OPTIMIZATION_AND_TASK_SPLITTING.md` - Technical deep dive
- `docs/TASK_SEPARATION_DEEP_DIVE.md` - Task splitting details
- `docs/HYBRID_COMPUTE_ARCHITECTURE.md` - Business model

### **Explore the Code:**
- `src/p2c2g/ml_coordinator.py` - ML implementation
- `src/p2c2g/task_splitter.py` - Task splitting strategies
- `examples/demo_ml_and_splitting.py` - Full demo

---

## Success Criteria

‚úÖ You should see:
- ML learning phase followed by optimization phase
- Performance improvements over time (faster, fewer failures)
- Different splitting strategies for different task types
- Full system rendering frames with parallel execution

‚úÖ Expected improvements:
- ~30% faster average completion time
- ~60-80% reduction in failure rate
- ~100% increase in peer utilization
- ~150% increase in throughput

---

## Questions?

Check the documentation:
- README.md - Project overview
- docs/IMPLEMENTATION_SUMMARY.md - What we built
- docs/HYBRID_COMPUTE_ARCHITECTURE.md - Why it works

Or explore the code - it's well-documented with docstrings! üöÄ
